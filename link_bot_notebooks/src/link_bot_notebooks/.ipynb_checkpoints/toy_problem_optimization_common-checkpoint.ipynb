{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "from IPython.display import display, Markdown, Pretty, HTML\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "def BOLD(x):\n",
    "    display(Markdown(\"**\" + str(x) + \"**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Simple Models\n",
    "\n",
    "We assume linear forms for all our functions:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "o_t &= As_t \\\\\n",
    "\\frac{\\partial o_t}{\\partial t} &= Bo_t + Cu_t && \\text{continuous} \\\\\n",
    "o_{t+1} &= o_t + \\Delta t(Bo_t + Cu_t) && \\text{discrete} \\\\\n",
    "\\hat{c}(s_t) &= (Ag - As_t)^TD(Ag - As_t)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStateSpaceModelWithQuadraticCost:\n",
    "    \n",
    "    def __init__(self, N, M, L):\n",
    "        \"\"\"\n",
    "        N: dimensionality of the full state\n",
    "        M: dimensionality in the reduced state\n",
    "        L: dimensionality in the actions\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.L = L\n",
    "        self.A = np.ndarray((M, N))\n",
    "        self.B = np.ndarray((1, M))\n",
    "        self.C = np.ndarray((M, L))\n",
    "        self.D = np.ndarray((M, M))\n",
    "        \n",
    "    def size(self):\n",
    "        return self.A.size + self.B.size + self.C.size + self.D.size\n",
    "        \n",
    "    def from_matrices(self, A, B, C, D):\n",
    "        assert A.size == self.A.size\n",
    "        assert B.size == self.B.size\n",
    "        assert C.size == self.C.size\n",
    "        assert D.size == self.D.size\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "        \n",
    "    def from_params(self, params):\n",
    "        assert len(params) == self.size(), \"Expected {:d} params, fot {:d}\".format(self.size(), len(params))\n",
    "        params = np.array(params)\n",
    "        n_A = self.A.size\n",
    "        self.A = params[0:n_A].reshape(self.A.shape)\n",
    "        n_B = n_A + self.B.size\n",
    "        self.B = params[n_A:n_B].reshape(self.B.shape)\n",
    "        n_C = n_B + self.C.size\n",
    "        self.C = params[n_B:n_C].reshape(self.C.shape)\n",
    "        n_D = n_C + self.D.size\n",
    "        self.D = params[n_C:n_D].reshape(self.D.shape)\n",
    "    \n",
    "    def to_params(self):\n",
    "        return np.concatenate((self.A.flatten(),\n",
    "                               self.B.flatten(),\n",
    "                               self.C.flatten(),\n",
    "                               self.D.flatten()))\n",
    "    \n",
    "    def reduce(self, s):\n",
    "        return np.dot(self.A, s)\n",
    "\n",
    "    def predict_from_s(self, s, u, dt):\n",
    "        o = np.dot(self.A, s)\n",
    "        o_ = o + (np.dot(self.B, o) + np.dot(self.C, u)) * dt\n",
    "        return o_\n",
    "\n",
    "    def predict_from_o(self, o, u, dt):\n",
    "        o_ = o + (np.dot(self.B, o) + np.dot(self.C, u)) * dt\n",
    "        return o_\n",
    "\n",
    "    def cost_of_s(self, s, g):\n",
    "        o = np.dot(self.A, s)\n",
    "        o_g = np.dot(self.A, g)\n",
    "        return np.dot((o_g - o).T, np.dot(self.D, o_g - o))\n",
    "    \n",
    "    def cost_of_o(self, o, g):\n",
    "        o_g = np.dot(self.A, g)\n",
    "        return np.dot((o_g - o).T, np.dot(self.D, o_g - o))\n",
    "    \n",
    "    def predict_cost_of_s(self, s, u, dt, g):\n",
    "        return self.cost_of_o(self.predict_from_s(s, u, dt), g)\n",
    "    \n",
    "    def predict_cost(self, o, u, dt, g):\n",
    "        return self.cost_of_o(self.predict_from_o(o, u, dt), g)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"Model reduction Matrix: {}\\n Dynamics matrices: {}, {}\\n Cost Matrix: {}\".format(self.A, self.B, self.C, self.D)\n",
    "    \n",
    "    def save(self, outfile):\n",
    "        np.savez(outfile, A=self.A, B=self.B, C=self.C, D=self.D)\n",
    "    \n",
    "    def load(self, infile):\n",
    "        matrices = np.load(infile)\n",
    "        self.A = matrices['A']\n",
    "        self.B = matrices['B']\n",
    "        self.C = matrices['C']\n",
    "        self.D = matrices['D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(data, model, goal, dt, objective_func, initial_params=None, tol=None, method='Powell', options={}, **kwargs):\n",
    "    \"\"\"\n",
    "    mutates the model that was passed in\n",
    "    \"\"\"\n",
    "        \n",
    "    def __objective(params):\n",
    "        model.from_params(params)\n",
    "        return objective_func(model=model, g=goal, data=data, dt=dt, **kwargs)\n",
    "    \n",
    "    if initial_params is None:\n",
    "        initial_params = np.random.randn(model.size())\n",
    "        \n",
    "    result = optimize.minimize(__objective, initial_params, method=method, options=options)\n",
    "    \n",
    "    if not result.success:\n",
    "        print(\"Status: {:d}, Message: {:s}\".format(result.status, result.message))\n",
    "        return result\n",
    "    print('Finished in {:d} iterations'.format(result.nit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error of our cost error\n",
    "$$ \\text{C}_\\theta = \\frac{1}{K}\\sum_1^K \\big[\\hat{c}(f_\\theta(s), f_\\theta(g)) - c(s_t)\\big]^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_cost(model, g, data):\n",
    "    err = np.zeros(len(data))\n",
    "    for i, (s, u, s_, c, c_) in enumerate(data):\n",
    "        err[i] = model.cost_of_s(s, g) - c\n",
    "       \n",
    "    return (err**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error of our state prediction error\n",
    "$$ \\text{SP}_\\theta = \\frac{1}{K}\\sum_1^K \\big[T_\\theta(f_\\theta(s_t), u_t) - f_\\theta(s_{t+1})\\big]^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_prediction(model, g, data, dt):\n",
    "    err = np.zeros(len(data))\n",
    "    for i, (s, u, s_, c, c_) in enumerate(data):\n",
    "        err[i] = np.linalg.norm(model.predict_from_s(s, u, dt) - model.reduce(s_))\n",
    "        \n",
    "    return (err**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error of our cost prediction error\n",
    "$$ \\text{CP}_\\theta = \\frac{1}{K}\\sum_1^K \\big[\\hat{c}_\\theta(T_\\theta(f_\\theta(s_t), u_t)) - c(s_{t+1})\\big]^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_prediction(model, g, data, dt):\n",
    "    err = np.zeros(len(data))\n",
    "    for i, (s, u, s_, c, c_) in enumerate(data):\n",
    "        o = model.reduce(s)\n",
    "        err[i] = np.linalg.norm(model.predict_cost(o, u, dt, g) - c_)\n",
    "        \n",
    "    return (err**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{CSP}_\\theta = \\alpha \\text{C}_\\theta + (1 - \\alpha ) \\text{SP}_\\theta + \\epsilon ||\\theta|| $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_prediction_objective(model, g, data, dt, alpha=0.5, regularization=1e-4):\n",
    "    \"\"\" return: MSE over all training examples \"\"\"\n",
    "    obj = alpha * state_prediction(model, g, data, dt)\n",
    "    obj += (1 - alpha) * current_cost(model, g, data)\n",
    "    obj += regularization * np.linalg.norm(model.to_params())\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{CCP}_\\theta = \\alpha \\text{C}_\\theta + (1 - \\alpha ) \\text{CP}_\\theta + \\epsilon ||\\theta|| $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_prediction_objective(model, g, data, dt, alpha=0.5, regularization=1e-4):\n",
    "    \"\"\" return: MSE over all training examples \"\"\"\n",
    "    obj = alpha * cost_prediction(model, g, data, dt)\n",
    "    obj += (1 - alpha) * current_cost(model, g, data)\n",
    "    obj += regularization * np.linalg.norm(model.to_params())\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for handling Gazebo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load some test data\n",
    "def load_data(log_file, g, extract_func):\n",
    "    log_data = np.loadtxt(log_file)\n",
    "    new_data = []\n",
    "    for i in range(log_data.shape[0] - 1):\n",
    "        s, u, c, = extract_func(log_data[i], g)\n",
    "        s_, u_, c_, = extract_func(log_data[i+1], g)\n",
    "        new_datum = [s, u, s_, c, c_]\n",
    "        new_data.append(new_datum)\n",
    "    return new_data\n",
    "\n",
    "def one_link_pos_extractor(row, g):\n",
    "    s = np.expand_dims(row[0:4], axis=1)\n",
    "    u = np.expand_dims(raw[4:6], axis=1)\n",
    "    c = (row[0] - g[0])**2 + (row[1] - g[1])**2\n",
    "    return s, u, c\n",
    "\n",
    "def two_link_pos_extractor(row, g):\n",
    "    s = np.expand_dims(row[0:6], axis=1)\n",
    "    u = np.expand_dims(row[8:10], axis=1)\n",
    "    c = (row[0] - g[0])**2 + (row[1] - g[1])**2\n",
    "    return s, u, c\n",
    "\n",
    "def two_link_pos_vel_extractor(row, g):\n",
    "    # 0   1   2   3   4   5   6   7   8   9  10  11\n",
    "    # x0 y0 vx0 vy0  x1  y1 vx1 vy1  x2  y2 vx2 vy2\n",
    "    s = np.expand_dims(row[[0,1,4,5,8,9]], axis=1)\n",
    "    u = np.expand_dims(row[[10,11]], axis=1)\n",
    "    c = (row[0] - g[0])**2 + (row[1] - g[1])**2\n",
    "    return s, u, c\n",
    "\n",
    "def five_link_pos_vel_extractor(row, g):\n",
    "    # 0   1   2   3   4   5   6   7   8   9  10  11 ...\n",
    "    # x0 y0 vx0 vy0  x1  y1 vx1 vy1  x2  y2 vx2 vy2 ...\n",
    "    s = np.expand_dims(row[[0,1,4,5,8,9,12,13,16,17,20,21]], axis=1)\n",
    "    u = np.expand_dims(row[[22,23]], axis=1)\n",
    "    c = (row[0] - g[0])**2 + (row[1] - g[1])**2\n",
    "    return s, u, c\n",
    "\n",
    "def link_pos_vel_extractor(N):\n",
    "    s_indeces = []\n",
    "    for i in range(0, 2*N, 4):\n",
    "        s_indeces.extend([i,i+1])\n",
    "    def __link_pos_vel_extractor(row, g):\n",
    "        s = np.expand_dims(row[s_indeces], axis=1)\n",
    "        u = np.expand_dims(row[[2*N - 2, 2*N - 1]], axis=1)\n",
    "        c = (row[0] - g[0])**2 + (row[1] - g[1])**2\n",
    "        return s, u, c\n",
    "    \n",
    "    return __link_pos_vel_extractor\n",
    "\n",
    "def link_pos_vel_extractor2(N):\n",
    "    s_indeces = []\n",
    "    for i in range(0, 2*N, 4):\n",
    "        s_indeces.extend([i,i+1])\n",
    "    def __link_pos_vel_extractor(row):\n",
    "        s = np.expand_dims(row[s_indeces], axis=1)\n",
    "        u = np.expand_dims(row[[2*N - 2, 2*N - 1]], axis=1)\n",
    "        return s, u\n",
    "    \n",
    "    return __link_pos_vel_extractor\n",
    "\n",
    "def load_train_test(filename, N, M, L, g, extract_func):\n",
    "    log_data = np.loadtxt(filename)\n",
    "    n_training_samples = log_data.shape[0]\n",
    "    train_x = np.ndarray((n_training_samples - 1, 3 * N + L))\n",
    "    train_y = np.ndarray((n_training_samples - 1, 2))\n",
    "    for i in range(n_training_samples - 1):\n",
    "        s, u, c, = extract_func(log_data[i], g)\n",
    "        s_, u_, c_, = extract_func(log_data[i+1], g)\n",
    "        train_x[i] = np.concatenate((s.flatten(), s_.flatten(), g.flatten(), u.flatten()))\n",
    "        train_y[i][0] = c\n",
    "        train_y[i][1] = c_\n",
    "\n",
    "    return n_training_samples, train_x, train_y\n",
    "\n",
    "def load_train(filename, n_steps, N, L, extract_func):\n",
    "    log_data = np.loadtxt(filename)\n",
    "    n_training_samples = log_data.shape[0]\n",
    "    n_trajs = int(n_training_samples / (n_steps + 1))\n",
    "    train_x = np.ndarray((n_steps + 1, N + L, n_trajs))\n",
    "    for k, d in enumerate(log_data):\n",
    "        s, u = extract_func(d)\n",
    "        i = int(k / (n_steps+1))\n",
    "        j = k % (n_steps+1)\n",
    "        train_x[j, :, i] = np.concatenate((s.flatten(), u.flatten()))\n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_gz_data(plt, new_data):\n",
    "    plt.figure()\n",
    "    plt.title(r\"Full State ($s$)\")\n",
    "    plt.plot([s[0][0,0] for s in new_data], label='x1')\n",
    "    plt.plot([s[0][1,0] for s in new_data], label='y1')\n",
    "    plt.plot([s[0][2,0] for s in new_data], label='x2')\n",
    "    plt.plot([s[0][3,0] for s in new_data], label='y2')\n",
    "    plt.ylabel(\"meters\")\n",
    "    plt.xlabel(\"time (steps)\")\n",
    "    plt.legend();\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(r\"Control Input ($u$)\")\n",
    "    plt.plot([s[1][0,0] for s in new_data], label='vx')\n",
    "    plt.plot([s[1][1,0] for s in new_data], label='vy')\n",
    "    plt.ylabel(\"m/s\")\n",
    "    plt.xlabel(\"time (steps)\")\n",
    "    plt.legend();\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(r\"Cost ($c$)\")\n",
    "    plt.plot([s[4] for s in new_data])\n",
    "    plt.xlabel(\"time (steps)\");\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_gz_data_v2(plt, new_data):\n",
    "    plt.figure()\n",
    "    plt.title(r\"Full State ($s$)\")\n",
    "    plt.plot([s[0][0,0] for s in new_data], label='x1')\n",
    "    plt.plot([s[0][1,0] for s in new_data], label='y1')\n",
    "    plt.plot([s[0][2,0] for s in new_data], label='x2')\n",
    "    plt.plot([s[0][3,0] for s in new_data], label='y2')\n",
    "    plt.plot([s[0][4,0] for s in new_data], label='x3')\n",
    "    plt.plot([s[0][5,0] for s in new_data], label='y3')\n",
    "    plt.ylabel(\"meters\")\n",
    "    plt.xlabel(\"time (steps)\")\n",
    "    plt.legend();\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(r\"Position of first point\")\n",
    "    plt.scatter([s[0][0,0] for s in new_data], [s[0][1,0] for s in new_data])\n",
    "    plt.ylabel(\"x (m)\")\n",
    "    plt.xlabel(\"y (m)\")\n",
    "    plt.legend();\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(r\"Control Input ($u$)\")\n",
    "    plt.plot([s[1][0,0] for s in new_data], label='fx')\n",
    "    plt.plot([s[1][1,0] for s in new_data], label='fy')\n",
    "    plt.ylabel(\"m/s\")\n",
    "    plt.xlabel(\"time (steps)\")\n",
    "    plt.legend();\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(r\"Cost ($c$)\")\n",
    "    plt.plot([s[4] for s in new_data])\n",
    "    plt.xlabel(\"time (steps)\");\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, data, g, dt, objective, initial_params=None, alpha=0.5, regularization=1e-5, print_model=True):\n",
    "    train(data, model, g, dt, objective, initial_params)\n",
    "    return eval_model(model, data, g, dt, alpha, regularization, print_model)\n",
    "    \n",
    "def eval_model(model, data, g, dt, alpha=0.5, regularization=1e-5, print_model=True):\n",
    "    pred_state_loss = state_prediction(model, g, data, dt)\n",
    "    cost_loss = current_cost(model, g, data)\n",
    "    pred_cost_loss = cost_prediction(model, g, data, dt)\n",
    "    pred_state_curr_cost_loss = state_prediction_objective(model, g, data, dt, alpha=alpha, regularization=regularization)\n",
    "    pred_cost_curr_cost_loss = cost_prediction_objective(model, g, data, dt, alpha=alpha, regularization=regularization)\n",
    "    reg_loss = regularization * np.linalg.norm(model.to_params())\n",
    "    eval_str = \"Loss Components:\\n\"\n",
    "    eval_str += \"\\tcurrent cost: {}\\n\".format(cost_loss)\n",
    "    eval_str += \"\\tpredict next latent state: {}\\n\".format(pred_state_loss)\n",
    "    eval_str += \"\\tpredict next cost: {}\\n\".format(pred_cost_loss)\n",
    "    eval_str += \"\\tregularization: {}\\n\".format(reg_loss)\n",
    "    eval_str += \"Complete Losses:\\n\"\n",
    "    eval_str += \"\\tpredict next latent state and current cost: {}\\n\".format(pred_state_curr_cost_loss)\n",
    "    eval_str += \"\\tpredict next cost and current cost: {}\\n\".format(pred_cost_curr_cost_loss)\n",
    "    print(eval_str)\n",
    "    if print_model:\n",
    "        print(model)\n",
    "    return cost_loss, pred_state_loss, pred_cost_loss, reg_loss\n",
    "\n",
    "def mean_dot_product(model, data, dt, g):\n",
    "    costs = [d[3:5] for d in data]\n",
    "    sum_of_dots = 0\n",
    "    for i, d in enumerate(data):\n",
    "        s = d[0]\n",
    "        u = d[1]\n",
    "        c_hat = model.cost_of_s(s, g)[0, 0]\n",
    "        c_hat_ = model.predict_cost_of_s(s, u, dt, g)[0,0]\n",
    "        sum_of_dots += np.dot(c_hat_ - c_hat, costs[i][1] - costs[i][0])[0]\n",
    "    return sum_of_dots / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Plotting & Introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_x_rollout(plt, model, data, dt, s0, g):\n",
    "    actions = [d[1] for d in data]\n",
    "    o = model.reduce(s0)\n",
    "    predicted_total_cost = 0.0\n",
    "    o_s = [o]\n",
    "    for u in actions:\n",
    "        c_hat = model.cost_of_o(o, g)\n",
    "        o = model.predict_from_o(o, u, dt)\n",
    "        o_s.append(o)\n",
    "        predicted_total_cost += c_hat\n",
    "    \n",
    "    states = [d[0] for d in data]\n",
    "    plt.figure()\n",
    "    plt.plot([s[0,0] for s in states], label='true x1')\n",
    "    plt.plot(np.squeeze(o_s), label='latent space o', linewidth=3, linestyle='--')\n",
    "    plt.xlabel(\"time steps\")\n",
    "    plt.ylabel(\"o\")\n",
    "    plt.legend();\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_total_cost\n",
    "\n",
    "def plot_xy_rollout(plt, model, data, dt, s0, g):\n",
    "    actions = [d[1] for d in data]\n",
    "    o = model.reduce(s0)\n",
    "    predicted_total_cost = 0.0\n",
    "    o_s = [o]\n",
    "    for u in actions:\n",
    "        c_hat = model.cost_of_o(o, g)\n",
    "        o = model.predict_from_o(o, u, dt)\n",
    "        o_s.append(o)\n",
    "        predicted_total_cost += c_hat\n",
    "    \n",
    "    states = [d[0] for d in data]\n",
    "    plt.figure()\n",
    "    plt.plot([s[0,0] for s in states], label='true x1')\n",
    "    plt.plot([s[1,0] for s in states], label='true y1')\n",
    "    plt.plot(np.squeeze(o_s), label='latent space o', linewidth=3, linestyle='--')\n",
    "    plt.xlabel(\"time steps\")\n",
    "    plt.ylabel(\"o\")\n",
    "    plt.legend();\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(plt, model, data, dt, g):\n",
    "    plt.figure()\n",
    "    \n",
    "    costs = [d[3] for d in data]\n",
    "    plt.scatter(np.arange(len(data)), costs, label='true cost')\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        s = d[0]\n",
    "        u = d[1]\n",
    "        c_hat = model.cost_of_s(s, g)[0, 0]\n",
    "        c_hat_ = model.predict_cost_of_s(s, u, dt, g)[0,0]\n",
    "        plt.plot([i, i+1], [c_hat, c_hat_], color='red')\n",
    "        plt.scatter([i], [c_hat], color='green', s=10) \n",
    "        \n",
    "    plt.title(\"Estimated vs True Cost\")\n",
    "    plt.xlabel(\"time steps\")\n",
    "    plt.ylabel(\"o\")\n",
    "    plt.legend();\n",
    "    plt.show()\n",
    "    \n",
    "def plot_o_rollout(plt, model, data, dt, g):\n",
    "    states = [d[0] for d in data]\n",
    "    actions = [d[1] for d in data]\n",
    "    o = model.reduce(states[0])\n",
    "    predicted_total_cost = 0.0\n",
    "    o_rollout = [o]\n",
    "    o_s = []\n",
    "    for s, u in zip(states, actions):\n",
    "        o_s.append(model.reduce(s))\n",
    "        c_hat = model.cost_of_o(o, g)\n",
    "        o = model.predict_from_o(o, u, dt)\n",
    "        o_rollout.append(o)\n",
    "        predicted_total_cost += c_hat\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Rollout in Reduction Space\")\n",
    "    plt.plot(np.squeeze(o_s), label='reduction of s_t')\n",
    "    plt.plot(np.squeeze(o_rollout), label='rollout from initial s_t', linewidth=3, linestyle='--')\n",
    "    plt.xlabel(\"time steps\")\n",
    "    plt.ylabel(\"o\")\n",
    "    plt.legend();\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costmap(plt, model, data, g, resolution=0.1, samples=5, spread=2):\n",
    "    colors = {}\n",
    "    min_sample = None\n",
    "    min_sample_cost = 1e9\n",
    "    for d in data:\n",
    "        state = d[0]\n",
    "        for i in range(samples):\n",
    "            s = state + np.random.randn(*state.shape) * spread\n",
    "            c = model.cost_of_s(s, g)[0,0]\n",
    "            xy = (s[0,0], s[1,0])\n",
    "            colors[xy] = c\n",
    "            if c < min_sample_cost:\n",
    "                min_sample_cost = c\n",
    "                min_sample = s\n",
    "            \n",
    "    plt.figure(figsize=(10,10))\n",
    "    xs = [k[0] for k in colors.keys()]\n",
    "    ys = [k[1] for k in colors.keys()]\n",
    "    plt.scatter(xs, ys, c=colors.values(), s=10, cmap='pink')\n",
    "    plt.axis(\"equal\")\n",
    "    return min_sample, min_sample_cost\n",
    "\n",
    "def plot_costmap_2(plt, model, data, g, resolution=0.1, minimum=-5, maximum=5):\n",
    "    N = int((maximum - minimum) / resolution)\n",
    "    colors = np.ndarray((N, N))\n",
    "    for i in range(N):\n",
    "        x = minimum + resolution * i\n",
    "        for j in range(N):\n",
    "            y = minimum + resolution * j\n",
    "            s = np.array([[x], [y], [0], [0], [0], [0]])\n",
    "            c = model.cost_of_s(s, g)[0,0]\n",
    "            colors[N - j - 1, i] = c\n",
    "            \n",
    "    plt.imshow(colors, interpolation=None, extent=[minimum, maximum, minimum, maximum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
