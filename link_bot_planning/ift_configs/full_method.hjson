{
  full_retrain_classifier: true
  trials_per_iteration: 1
  trials_generator_type: random
  fine_tune_classifier: {
    fine_tune_conv: true
    fine_tune_dense: true
    fine_tune_lstm: true
    fine_tune_output: true
    learning_rate: 0.001
    augmentation_config_dir: /media/shared/pretransfer_initial_configs/car3/
    epochs: 5
    early_stopping: false
  }
  fine_tune_recovery: null
  planner_params_update: {
    termination_criteria:
    {
    }
  }
  results_to_classifier_dataset: {
    val_split: 0.0
    test_split: 0.0
  }
  results_to_recovery_dataset: null
  labeling_params_update: {
    augmentation: {
      type: v3
      on_invalid_aug: "original"  # one of [drop, original]
      invariance_model: /media/shared/invariance_trials/relu/July_16_11-30-35_47c46e451e/best_checkpoint
    }
  }
  pretraining: {
    use_pretraining: false # at the moment I'm running this as a separate step
    # pretraining_type: augmentation
    # model_hparams_update_filename: ../link_bot_classifiers/hparams/aug.hjson
    # augmentation_config_dir: pretransfer_initial_configs/long_hook/
    # epochs: 100
    # batch_size: 16
    # fine_tune_conv: false
    # fine_tune_dense: false
    # fine_tune_lstm: false
    # fine_tune_output: true
  }
}
