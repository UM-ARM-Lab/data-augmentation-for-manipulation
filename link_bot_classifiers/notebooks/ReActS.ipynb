{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReActS: Recovering Action Sequences\n",
    "\n",
    "This notebook analyses the datasets collected in environments with physical constraints, trying to find & analyze recovering action sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "from time import perf_counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "from colorama import Fore\n",
    "\n",
    "from link_bot_data.dynamics_dataset import DynamicsDataset\n",
    "from state_space_dynamics import model_utils\n",
    "from moonshine.gpu_config import limit_gpu_mem\n",
    "from link_bot_pycommon.pycommon import print_dict\n",
    "from IPython.display import HTML\n",
    "from link_bot_pycommon.get_scenario import get_scenario\n",
    "from moonshine.moonshine_utils import dict_of_sequences_to_sequence_of_dicts_tf, dict_of_sequences_to_sequence_of_dicts, numpify\n",
    "import matplotlib.pyplot as plt\n",
    "from link_bot_data.classifier_dataset_utils import *\n",
    "from link_bot_classifiers import classifier_utils\n",
    "from matplotlib import rc\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "plt.style.use(\"slides\")\n",
    "\n",
    "limit_gpu_mem(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mRestored from ss_log_dir/tf2_rope/0/ckpt-40\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/1/ckpt-44\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/2/ckpt-45\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/3/ckpt-43\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/4/ckpt-40\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/5/ckpt-38\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/6/ckpt-40\u001b[39m\n",
      "\u001b[36mRestored from ss_log_dir/tf2_rope/7/ckpt-49\u001b[39m\n",
      "\u001b[36mRestored from log_data/rope_2_seq/May_24_01-12-08_617a0bee2a/ckpt-5\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "take = None\n",
    "scenario = get_scenario(\"link_bot\")\n",
    "dynamics_dataset = DynamicsDataset([pathlib.Path(\"./fwd_model_data/rope_more_obs_big/\")])\n",
    "n_total_train_examples = 8250\n",
    "tf_dataset = dynamics_dataset.get_datasets(mode='train', take=take)\n",
    "model_dirs = [pathlib.Path(f\"./ss_log_dir/tf2_rope/{i}\") for i in range(8)]\n",
    "fwd_models, _ = model_utils.load_generic_model(model_dirs)\n",
    "\n",
    "classifier_model_dir = pathlib.Path('log_data/rope_2_seq/May_24_01-12-08_617a0bee2a')\n",
    "classifier_model = classifier_utils.load_generic_model(classifier_model_dir, scenario=scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_params = {\n",
    "    'threshold': 0.10,\n",
    "    'state_key': 'link_bot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_recovered(environment, state, action, next_state, threshold):\n",
    "    actions = tf.expand_dims(action, axis=0)\n",
    "    prediction = fwd_models.propagate_differentiable(environment, state, actions)[1]\n",
    "    is_recovered = tf.linalg.norm(prediction['link_bot'] - next_state['link_bot']) < threshold\n",
    "    return is_recovered, prediction\n",
    "\n",
    "def check_sequence(example):\n",
    "    inputs, outputs = example\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    actions = []\n",
    "    for start_t  in range(0, dynamics_dataset.max_sequence_length - 1):\n",
    "        action = inputs['action'][start_t]\n",
    "        state = {\n",
    "            'link_bot': outputs['link_bot'][start_t]\n",
    "        }\n",
    "        next_state = {\n",
    "            'link_bot': outputs['link_bot'][start_t + 1]\n",
    "        }\n",
    "        environment = scenario.get_environment_from_example(example)\n",
    "        is_recovered, prediction = check_is_recovered(environment, state, action, next_state, labeling_params['threshold'])\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        actuals.append(state)\n",
    "        actions.append(action)\n",
    "        is_recovered_sequence.append(is_recovered)\n",
    "        if is_recovered:\n",
    "            if len(is_recovered_sequence) > 1:\n",
    "                actuals.append(next_state)\n",
    "                return True, {\n",
    "                    'actuals': actuals,\n",
    "                    'actions': actions,\n",
    "                    'environment': environment,\n",
    "                    'predictions': predictions,\n",
    "                    'is_recovered_sequence': is_recovered_sequence,\n",
    "                }\n",
    "    return False, None\n",
    "\n",
    "def sample_actions(m):\n",
    "    return tf.random.uniform(shape=[m, 1, 2], minval=-0.15, maxval=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "tf.random.set_seed(0)\n",
    "n_reacts_examples = 0 \n",
    "n_actions_sampled = 50\n",
    "recovering_examples = []\n",
    "for example in tf_dataset:\n",
    "    inputs, outputs = example\n",
    "    environment = scenario.get_environment_from_example(example)\n",
    "    environment_batched = {k:tf.stack([v]*n_actions_sampled, axis=0) for k,v in environment.items()}\n",
    "    for start_t  in range(0, dynamics_dataset.max_sequence_length - 2):\n",
    "        action = inputs['action'][start_t]\n",
    "        state_vec = outputs['link_bot'][start_t]\n",
    "        start_state_np = {\n",
    "            'link_bot': state_vec.numpy(),\n",
    "        }\n",
    "        random_actions = sample_actions(n_actions_sampled)\n",
    "        \n",
    "        state_batched = tf.expand_dims(tf.stack([state_vec]*n_actions_sampled, axis=0), axis=1)\n",
    "        state_dict = {\n",
    "            'link_bot': state_batched,\n",
    "        }\n",
    "        predictions = fwd_models.propagate_differentiable_batched(start_states=state_dict,\n",
    "                                                                  actions=random_actions)\n",
    "        p_needs_recovery = classifier_model.check_constraint_differentiable_batched_tf(environment=environment_batched,\n",
    "                                                                                             predictions=predictions,\n",
    "                                                                                             actions=random_actions)\n",
    "        needs_recovery = p_needs_recovery < 0.5\n",
    "        if tf.reduce_all(needs_recovery):\n",
    "#             plt.figure()\n",
    "#             ax = plt.gca()\n",
    "#             scenario.plot_state(ax, start_state_np, color='r', s=50, zorder=1)\n",
    "#             scenario.plot_environment(ax, numpify(environment))\n",
    "#             for action in random_actions:\n",
    "#                 scenario.plot_action(ax, start_state_np, action[0].numpy(), color='r', s=50, zorder=1)\n",
    "#             print(p_needs_recovery)\n",
    "#             plt.show(block=True)\n",
    "            is_recovered_sequence = []\n",
    "            is_recovering, recovering_data = check_sequence(example)\n",
    "            if is_recovering:\n",
    "                recovering_examples.append(recovering_data)\n",
    "print(len(recovering_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reacts_examples = len(recovering_examples)\n",
    "print(f\"{n_reacts_examples / n_total_train_examples * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "def animate(recovering_example):\n",
    "    anim = scenario.animate_recovering_actions_sequence(environment=numpify(recovering_example['environment']),\n",
    "                                                        actions=recovering_example['actions'],\n",
    "                                                        actual=recovering_example['actuals'],\n",
    "                                                        predictions=recovering_example['predictions'],\n",
    "                                                        fps=0.5)\n",
    "    return anim\n",
    "\n",
    "# anim = animate(recovering_examples[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
