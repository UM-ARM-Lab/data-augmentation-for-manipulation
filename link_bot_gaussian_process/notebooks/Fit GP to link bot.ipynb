{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow as gpf\n",
    "import numpy as np\n",
    "import gpflow.multioutput.kernels as mk\n",
    "import gpflow.multioutput.features as mf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "from link_bot_notebooks import experiments_util\n",
    "from link_bot_gaussian_process.link_bot_gp import LinkBotGP\n",
    "from link_bot_gaussian_process import data_reformatting, error_metrics\n",
    "from tabulate import tabulate\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "np.set_printoptions(suppress=True, precision=4, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"slides\")\n",
    "plt.style.use(\"slides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_inverse_data2(data, traj_idx_start=0, traj_idx_end=-1, examples_per_traj=5):\n",
    "    \"\"\" this assumes trajectories have one constants control input \"\"\"\n",
    "    states = data['states'][traj_idx_start:traj_idx_end]\n",
    "    actions = data['actions'][traj_idx_start:traj_idx_end]\n",
    "\n",
    "    n_traj, max_n_steps, n_state = states.shape\n",
    "    start_indeces = np.random.randint(1, max_n_steps, size=(n_traj * examples_per_traj))\n",
    "    end_indeces = np.random.randint(1, max_n_steps, size=(n_traj * examples_per_traj))\n",
    "    for i in np.argwhere(start_indeces > end_indeces):\n",
    "        # https://stackoverflow.com/questions/14836228/is-there-a-standardized-method-to-swap-two-variables-in-python\n",
    "        # yes, this is correct.\n",
    "        start_indeces[i], end_indeces[i] = end_indeces[i], start_indeces[i]\n",
    "    for i in np.argwhere(start_indeces == end_indeces):\n",
    "        if end_indeces[i] == max_n_steps - 1:\n",
    "            start_indeces[i] -= 1\n",
    "        else:\n",
    "            end_indeces[i] += 1\n",
    "\n",
    "    traj_indeces = np.repeat(np.arange(n_traj), examples_per_traj)\n",
    "    delta = states[traj_indeces, end_indeces] - states[traj_indeces, start_indeces]\n",
    "\n",
    "    delta_flat = delta.reshape(-1, 6)\n",
    "    head_delta_mag = np.linalg.norm(delta_flat[:, 4:6], axis=1, keepdims=True)\n",
    "    actions_flat = actions[traj_indeces, 0]\n",
    "    num_steps_flat = (end_indeces - start_indeces).reshape(-1, 1)\n",
    "    mag_flat = np.linalg.norm(actions_flat, axis=1).reshape(-1, 1)\n",
    "    actions_flat_scaled = actions_flat / np.linalg.norm(actions_flat, axis=1).reshape(-1, 1)\n",
    "    # the action representation here is cos(theta), sin(theta), magnitude\n",
    "    # I think this is better than predicting just components or mag/theta\n",
    "    # because theta is discontinuous and GPs assume smoothness\n",
    "    x = np.concatenate((delta_flat, head_delta_mag), axis=1)\n",
    "    y = np.concatenate((actions_flat_scaled, mag_flat, num_steps_flat), axis=1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1063  0.0107  0.0007  0.3419 -0.0005  0.3429  0.3429]\n",
      " [ 0.1155  0.0114  0.002   0.4281 -0.0003  0.43    0.43  ]\n",
      " [ 0.2837 -0.0033  0.3172  0.8384  0.0291  1.2297  1.23  ]\n",
      " [ 0.7297  0.2957  0.2058  1.6358  0.0184  1.8392  1.8393]\n",
      " [ 0.6014  0.2264  0.003   1.0537 -0.      1.0562  1.0562]\n",
      " [-0.0478  0.334  -0.4     0.1182 -0.3032  0.2238  0.3769]\n",
      " [-0.0008  0.0264 -0.023   0.0178 -0.0229  0.0178  0.029 ]\n",
      " [-0.0002  0.0367 -0.0025  0.036  -0.0241  0.0155  0.0286]\n",
      " [-0.0019  0.02   -0.0387  0.0014 -0.0238  0.0193  0.0306]\n",
      " [-0.0021  0.0226 -0.04    0.0014 -0.0243  0.0193  0.0311]]\n",
      "[[ 0.217   0.9762  0.5488  8.    ]\n",
      " [ 0.217   0.9762  0.5488 10.    ]\n",
      " [ 0.217   0.9762  0.5488 28.    ]\n",
      " [ 0.217   0.9762  0.5488 43.    ]\n",
      " [ 0.217   0.9762  0.5488 25.    ]\n",
      " [-0.7776  0.6288  0.4376 13.    ]\n",
      " [-0.7776  0.6288  0.4376  1.    ]\n",
      " [-0.7776  0.6288  0.4376  1.    ]\n",
      " [-0.7776  0.6288  0.4376  1.    ]\n",
      " [-0.7776  0.6288  0.4376  1.    ]]\n"
     ]
    }
   ],
   "source": [
    "inv_train_data = format_inverse_data2(data, train_idx_start, train_idx_end)\n",
    "inv_train_x = inv_train_data[0]\n",
    "inv_train_y = inv_train_data[1]\n",
    "print(inv_train_x[:10])\n",
    "print(inv_train_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"240_50_random4.npz\")\n",
    "train_idx_start = 0\n",
    "train_idx_end = 200\n",
    "test_idx_start = 200\n",
    "test_idx_end = 240\n",
    "\n",
    "fwd_train_data = data_reformatting.format_forward_data(data, train_idx_start, train_idx_end)\n",
    "fwd_train_x_flat, fwd_train_y, fwd_train_u_flat, fwd_train_x, fwd_train_x_trajs, fwd_train_u_trajs = fwd_train_data\n",
    "fwd_test_data = data_reformatting.format_forward_data(data, test_idx_start, test_idx_end)\n",
    "fwd_test_x_flat, fwd_test_y, fwd_test_u_flat, fwd_test_x, fwd_test_x_trajs, fwd_test_u_trajs = fwd_test_data\n",
    "\n",
    "inv_train_data = format_inverse_data2(data, train_idx_start, train_idx_end)\n",
    "inv_train_x = inv_train_data[0]\n",
    "inv_train_y = inv_train_data[1]\n",
    "inv_test_data = format_inverse_data2(data, test_idx_start, test_idx_end)\n",
    "inv_test_x = inv_test_data[0]\n",
    "inv_test_y = inv_test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtraining time: 38.37777233123779s\u001b[39m\n",
      "\u001b[33mtraining time: 18.609022855758667s\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=False, per_process_gpu_memory_fraction=0.1))\n",
    "gpf.reset_default_session(config=config)\n",
    "fwd_model = LinkBotGP()\n",
    "inv_model = LinkBotGP()\n",
    "\n",
    "fwd_model.train(fwd_train_x, fwd_train_y, maximum_training_iterations=300, n_inducing_points=10)\n",
    "inv_model.train(inv_train_x, inv_train_y, maximum_training_iterations=300, n_inducing_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSaving model to /home/pmitrano/catkin_ws/src/link_bot/link_bot_gaussian_process/notebooks/log_data/separate_independent/May_31_18-03-43__bf505bde20__gpf/fwd_model\u001b[39m\n",
      "\u001b[36mSaving model to /home/pmitrano/catkin_ws/src/link_bot/link_bot_gaussian_process/notebooks/log_data/separate_independent/May_31_18-03-43__bf505bde20__gpf/inv_model\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "log_path = experiments_util.experiment_name('separate_independent', 'gpf')\n",
    "fwd_model.save(log_path, 'fwd_model')\n",
    "inv_model.save(log_path, 'inv_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| error metric             |    min |     max |   mean |   median |    std |\n",
      "|--------------------------|--------|---------|--------|----------|--------|\n",
      "| tail position error (m)  |  0.000 |   0.091 |  0.020 |    0.014 |  0.018 |\n",
      "| mid position error (m)   |  0.000 |   0.087 |  0.018 |    0.011 |  0.018 |\n",
      "| head position error (m)  |  0.000 |   0.058 |  0.005 |    0.005 |  0.003 |\n",
      "| total position error (m) |  0.005 |   0.169 |  0.043 |    0.032 |  0.032 |\n",
      "| speed (m/s)              |  0.000 |   0.704 |  0.192 |    0.159 |  0.161 |\n",
      "| angle (deg)              |  0.017 | 123.466 | 15.613 |   10.172 | 16.873 |\n",
      "| time steps               |  0.072 |  23.366 |  6.811 |    7.030 |  3.949 |\n"
     ]
    }
   ],
   "source": [
    "headers = ['error metric', 'min', 'max', 'mean', 'median', 'std']\n",
    "aggregate_metrics = np.vstack((error_metrics.fwd_model_error_metrics(fwd_model, fwd_test_x, fwd_test_y),\n",
    "                               error_metrics.inv_model_error_metrics(inv_model, inv_test_x, inv_test_y)))\n",
    "table = tabulate(aggregate_metrics, headers=headers, tablefmt='github', floatfmt='6.3f')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2937  0.0983  0.2885 11.5261]\n",
      " [ 0.0133 -0.0592  0.2556 10.7725]\n",
      " [-0.8878  0.4407  0.3799 13.6736]\n",
      " [-0.8796  0.7319  0.5178 17.1982]\n",
      " [-0.9876  0.5637  0.4269 14.8194]\n",
      " [-0.4585  0.8119  0.7034 23.2311]\n",
      " [-0.6943  0.9977  0.4688 15.7133]\n",
      " [-0.6796  1.0041  0.4708 15.7465]\n",
      " [-0.3972  0.8191  0.7212 23.1459]\n",
      " [-0.4682  0.673   0.3708 13.3433]]\n",
      "2.5900835448556085\n"
     ]
    }
   ],
   "source": [
    "pred_y = inv_model.model.predict_y(inv_test_x)[0]\n",
    "print(inv_model.model.predict_y(inv_test_x[:10])[0])\n",
    "print(np.max(inv_test_x[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.8476 13.9709 11.9784 16.0009 12.533  14.6802 16.6578 20.5387 14.2149 18.4198 28.7587 20.1584 27.5322 27.3138 28.0619 20.1163 17.5867 23.4253 30.2449 18.1358 25.803  18.3925 22.1562 14.3646\n",
      " 26.9416 12.0512 12.661  11.9386 13.3199 13.9508 13.0564 12.2449 12.2246 12.5368 27.2607 14.6251 15.6519 20.3891 16.951  24.2075 26.6258 24.1772 17.2405 21.016  16.5319 14.9099 26.1676 13.3873\n",
      " 13.4172 22.1503 13.3085 14.7432 13.116  15.288  13.1866 12.3337 14.7804 28.0985 16.538  22.2211 29.39   18.3385 24.0295 13.8929 19.8235 24.0749 29.207  15.7692 15.2029 23.7053 16.422  18.3416\n",
      " 14.3857 17.0854 13.1258 12.1861 14.4205 12.6347 11.9847 11.967  19.4527 21.7772 19.477  21.7833 13.6795 14.527  14.879  16.1995 12.9003 17.4778 15.5661 26.6871 14.8429 26.3579 12.6861 23.4427\n",
      " 30.638  29.9074 12.5839 31.2332 20.2655 28.12   13.4489 15.4485 13.3947 25.9973 25.7606 14.0153 12.6484 19.277  28.069  14.3488 18.2828 25.7044 31.0006 13.5881 15.5521 13.7709 12.1743 13.6042\n",
      " 24.3793 25.9941 14.2547 26.6715 13.6363 14.233  15.3314 17.493  14.4153 12.0146 12.1744 12.0497 11.9376 11.9987 11.9243 13.3581 14.2696 13.7127 15.7705 14.8842 12.5228 24.2056 24.7194 22.759\n",
      " 14.801  12.0736 13.09   12.272  11.9961 12.6019 15.4212 12.4253 24.2354 23.2023 19.6323 27.2535 14.9081 24.28   20.8644 13.931  12.772  20.6873 13.3438 15.0698 13.4127 23.8089 18.9319 21.1356\n",
      " 13.4728 21.9531 26.2048 28.4921 19.1627 18.2072 28.6638 12.6499 12.5778 12.3572 13.9931 13.3858 12.7011 11.9903 12.3142 11.9829 14.2158 11.892  12.4573 11.9466 12.4372 11.9393 18.1163 13.1416\n",
      " 12.2123 15.5383 20.6084 12.8355 12.1342 16.0169 16.573  15.5573]\n"
     ]
    }
   ],
   "source": [
    "print(pred_y[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_A = np.zeros(2)\n",
    "untrained_B = np.eye(2)\n",
    "\n",
    "trained_A = np.array([[0.005394, -0.002816], [0.001254, -0.00443]])\n",
    "trained_B = np.array([[0.366756,  0.017419], [0.023738, 0.378886]])\n",
    "\n",
    "# FIXME: This are probabily wrong now\n",
    "def predict_linear_model(A, B, x_traj, u_traj):\n",
    "    dt = 0.1\n",
    "    initial_x = x_traj[0][0:2]  # select just the tail\n",
    "    xs = np.ndarray((u_traj.shape[0], 2))\n",
    "    xs[0] = initial_x\n",
    "    x = initial_x\n",
    "    for i, u in enumerate(u_traj):\n",
    "        x = x + dt*A@x + dt*B@u\n",
    "        xs[i] = x\n",
    "    return xs\n",
    "\n",
    "def one_step_predict_linear_model(A, B, x_traj, u_traj):\n",
    "    dt = 0.1\n",
    "    xs = np.ndarray((u_traj.shape[0], 2))\n",
    "    xs[0] = x_traj[0][0:2]\n",
    "    for i in range(u_traj.shape[0] - 1):\n",
    "        u = u_traj[i]\n",
    "        x = x_traj[i][0:2]\n",
    "        x_next = x + dt*A@x + dt*B@u\n",
    "        xs[i+1] = x_next\n",
    "    return xs\n",
    "\n",
    "def batch_one_step_predict_linear_model(A, B, batch_x_traj, batch_u_traj):\n",
    "    n_traj, n_step, _  = batch_x_traj.shape\n",
    "    xs = np.ndarray((n_traj, n_step, 2))\n",
    "    for i, (x_traj, u_traj) in enumerate(zip(batch_x_traj, batch_u_traj)):\n",
    "        xs[i] = one_step_predict_linear_model(A, B, x_traj, u_traj)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_displacement = np.linalg.norm(fwd_test_y[:, 0:2], axis=1) + np.linalg.norm(fwd_test_y[:, 2:4], axis=1) + np.linalg.norm(fwd_test_y[:, 4:6], axis=1)\n",
    "print(\"Some stats about the testing data:\")\n",
    "print('min displacement in test', np.min(total_displacement))\n",
    "print('max displacement in test', np.max(total_displacement))\n",
    "print('mean displacement in test', np.mean(total_displacement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error for linear models\n",
    "untrained_linear_data = batch_one_step_predict_linear_model(untrained_A, untrained_B, fwd_test_x_trajs, fwd_test_u_trajs)\n",
    "trained_linear_data = batch_one_step_predict_linear_model(trained_A, trained_B, fwd_test_x_trajs, fwd_test_u_trajs)\n",
    "\n",
    "untrained_linear_tail_error = np.linalg.norm(untrained_linear_data - fwd_test_x_trajs[:, :, :2], axis=2)\n",
    "trained_linear_tail_error = np.linalg.norm(trained_linear_data - fwd_test_x_trajs[:, :, :2], axis=2)\n",
    "print(\"Stats about the old linear models:\")\n",
    "print(\"untrained linear model tail position error (min/max/mean/median)\", untrained_linear_tail_error.min(), untrained_linear_tail_error.max(), untrained_linear_tail_error.mean(), np.median(untrained_linear_tail_error), np.std(untrained_linear_tail_error))\n",
    "print(\"trained linear model tail position error (min/max/mean/median)\", trained_linear_tail_error.min(), trained_linear_tail_error.max(), trained_linear_tail_error.mean(), np.median(trained_linear_tail_error), np.std(trained_linear_tail_error))\n",
    "print(np.unravel_index(untrained_linear_tail_error.argmax(), untrained_linear_tail_error.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fwd_model, traj, steps=1, initial_variance = 0.00001):\n",
    "    test_x_traj, test_u_traj  = traj\n",
    "    traj_length = test_x_traj.shape[0]\n",
    "    \n",
    "    assert steps < traj_length, \"steps {} > traj length {}!\".format(steps, traj_length)\n",
    "    \n",
    "    if test_x_traj.shape[0] > test_u_traj.shape[0]:\n",
    "        test_x_traj = test_x_traj[:test_u_traj.shape[0]]\n",
    "        \n",
    "    mu_combined_test_x = np.hstack((test_x_traj, test_u_traj))\n",
    "        \n",
    "    # define the initial distribution\n",
    "    mu_combined_test_x_t = mu_combined_test_x[0]\n",
    "    sigma_combined_test_x = np.eye(fwd_model.n_inputs) * initial_variance\n",
    "    # assume no control variance\n",
    "    sigma_combined_test_x[-2, -2] = 0\n",
    "    sigma_combined_test_x[-1, -1] = 0\n",
    "    \n",
    "    # sample from that initial distribution to get initial particles to feed into the GP\n",
    "    num_particles = 50\n",
    "    combined_x_t_particles = np.random.multivariate_normal(mu_combined_test_x_t, sigma_combined_test_x, num_particles)\n",
    "    particles = np.zeros((steps, num_particles, fwd_model.n_inputs))\n",
    "    \n",
    "    for t in range(steps):\n",
    "        particles[t] = combined_x_t_particles\n",
    "        combined_x_t_particles_relative = data_reformatting.make_relative_to_head(combined_x_t_particles)\n",
    "        mu_delta_x_t_plus_1s, var_delta_x_t_plus_1s = fwd_model.model.predict_y(combined_x_t_particles_relative)\n",
    "        # sample point from the gaussian prediction\n",
    "        combined_x_t_plus_1_particles = np.empty_like(combined_x_t_particles)\n",
    "        for j, (mu_delta_x_t_plus_1_j, var_delta_x_t_plus_1_j) in enumerate(zip(mu_delta_x_t_plus_1s, var_delta_x_t_plus_1s)):\n",
    "            # We assumed that the GPs are independant for each output dimension, so the full covariance matrix is diagonal\n",
    "            sigma_delta_x_t_plus_1_j = np.diag(var_delta_x_t_plus_1_j)\n",
    "            u_t_plus_1_j = test_u_traj[t + 1]\n",
    "            delta_delta_x_t_j = np.random.multivariate_normal(mu_delta_x_t_plus_1_j, sigma_delta_x_t_plus_1_j)\n",
    "            # predict only gives the delta position, so we have to integrate here\n",
    "            delta_delta_combined_x_t_j = np.hstack((delta_delta_x_t_j, [0, 0]))\n",
    "            combined_x_t_plus_1_particles[j] =  combined_x_t_particles[j] + delta_delta_combined_x_t_j\n",
    "        \n",
    "        combined_x_t_particles = combined_x_t_plus_1_particles\n",
    "            \n",
    "    return particles, test_x_traj, test_u_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_no_ground_truth(my_model, initial_x, u, steps=1, initial_variance = 0.00001):\n",
    "    # define the initial distribution\n",
    "    mu_combined_x_t =  np.hstack((initial_x, u))\n",
    "    sigma_combined_x_t = np.eye(my_model.n_inputs) * initial_variance\n",
    "    # assume no control variance\n",
    "    sigma_combined_x_t[-2, -2] = 0\n",
    "    sigma_combined_x_t[-1, -1] = 0\n",
    "    \n",
    "    # sample from that initial distribution to get initial particles to feed into the GP\n",
    "    num_particles = 50\n",
    "    combined_x_t_particles = np.random.multivariate_normal(mu_combined_x_t, sigma_combined_x_t, num_particles)\n",
    "    particles = np.zeros((steps, num_particles, my_model.n_inputs))\n",
    "    \n",
    "    x_traj = np.reshape(initial_x, [1, -1])\n",
    "    u_traj = np.ones((steps, 2))*u\n",
    "    trained_linear_data = predict_linear_model(trained_A, trained_B, x_traj, u_traj)\n",
    "\n",
    "    for t in range(steps):\n",
    "        particles[t] = combined_x_t_particles\n",
    "        combined_x_t_particles_relative = data_reformatting.make_relative_to_head(combined_x_t_particles)\n",
    "        mu_delta_x_t_plus_1s, var_delta_x_t_plus_1s = fwd_model.model.predict_y(combined_x_t_particles_relative)\n",
    "        # sample point from the gaussian prediction\n",
    "        combined_x_t_plus_1_particles = np.empty_like(combined_x_t_particles)\n",
    "        for j, (mu_delta_x_t_plus_1_j, var_delta_x_t_plus_1_j) in enumerate(zip(mu_delta_x_t_plus_1s, var_delta_x_t_plus_1s)):\n",
    "            # We assumed that the GPs are independant for each output dimension, so the full covariance matrix is diagonal\n",
    "            sigma_delta_x_t_plus_1_j = np.diag(var_delta_x_t_plus_1_j)\n",
    "            delta_delta_x_t_j = np.random.multivariate_normal(mu_delta_x_t_plus_1_j, sigma_delta_x_t_plus_1_j)\n",
    "            # predict only gives the delta position, so we have to integrate here\n",
    "            delta_delta_combined_x_t_j = np.hstack((delta_delta_x_t_j, [0, 0]))\n",
    "            combined_x_t_plus_1_particles[j] =  combined_x_t_particles[j] + delta_delta_combined_x_t_j\n",
    "        \n",
    "        combined_x_t_particles = combined_x_t_plus_1_particles\n",
    "            \n",
    "    return particles, trained_linear_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "def plot_predict(particles, test_x_traj=None, test_u_traj=None, untrained_linear_data=None, trained_linear_data=None):\n",
    "    T = particles.shape[0]\n",
    "    if test_x_traj is not None:\n",
    "        x0s = [test_x_traj[0, 0], test_x_traj[0, 2], test_x_traj[0, 4]]\n",
    "        y0s = [test_x_traj[0, 1], test_x_traj[0, 3], test_x_traj[0, 5]]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    x_t_particles_data = []\n",
    "    for x_t_particle in particles[0]:\n",
    "        x_t_particles_xs = [x_t_particle[0], x_t_particle[2], x_t_particle[4]]\n",
    "        x_t_particles_ys = [x_t_particle[1], x_t_particle[3], x_t_particle[5]]\n",
    "        line = plt.plot(x_t_particles_xs, x_t_particles_ys, color='black', alpha=0.2)[0]\n",
    "        x_t_particles_data.append(line)\n",
    "            \n",
    "    if test_x_traj is not None:\n",
    "        plt.plot(x0s, y0s, color='orange')\n",
    "        \n",
    "    x_next_data = []\n",
    "    if test_x_traj is not None:\n",
    "        x_t_plus_1 = test_x_traj[1]\n",
    "        xs_next = [x_t_plus_1[0], x_t_plus_1[2], x_t_plus_1[4]]\n",
    "        ys_next = [x_t_plus_1[1], x_t_plus_1[3], x_t_plus_1[5]]\n",
    "        x_next_data = plt.plot(xs_next, ys_next, color='blue')[0]\n",
    "        \n",
    "    untrained_linear_x_next_data = []\n",
    "    if untrained_linear_data is not None:\n",
    "        untrained_linear_x_t_plus_1 = untrained_linear_data[1]\n",
    "        untrained_linear_x_next_data = plt.scatter(untrained_linear_x_t_plus_1[0], untrained_linear_x_t_plus_1[1], color='r')\n",
    "    trained_linear_x_next_data = []\n",
    "    if trained_linear_data is not None:\n",
    "        trained_linear_x_t_plus_1 = trained_linear_data[1]\n",
    "        trained_linear_x_next_data = plt.scatter(trained_linear_x_t_plus_1[0], trained_linear_x_t_plus_1[1], color='g')\n",
    "\n",
    "    if test_x_traj is not None:\n",
    "        plt.quiver(test_x_traj[0, 4], test_x_traj[0, 5], test_u_traj[0, 0], test_u_traj[0, 1], color='black', width=0.004)\n",
    "\n",
    "    plt.xlabel(\"x (m)\")\n",
    "    plt.ylabel(\"y (m)\")\n",
    "    plt.xlim([-7,7])\n",
    "    plt.ylim([-7,7])\n",
    "    custom_lines = [Line2D([0], [0], color='black', lw=1, alpha=0.1),\n",
    "                    Line2D([0], [0], color='orange', lw=1),\n",
    "                    Line2D([0], [0], color='blue', lw=1),\n",
    "                    Line2D([0], [0], color='red', lw=1),\n",
    "                    Line2D([0], [0], color='green', lw=1),\n",
    "                   ]\n",
    "\n",
    "    l = plt.legend(custom_lines, ['predictions', r'$x_0$', r'$x_t$', 'linear (init)', 'linear (fine-tuned)'])\n",
    "    \n",
    "    def update(t):\n",
    "        x_t_particles = particles[t]\n",
    "        for x_t_particle_d, x_t_particle in zip(x_t_particles_data, x_t_particles):\n",
    "            x_t_particles_xs = [x_t_particle[0], x_t_particle[2], x_t_particle[4]]\n",
    "            x_t_particles_ys = [x_t_particle[1], x_t_particle[3], x_t_particle[5]]\n",
    "            x_t_particle_d.set_xdata(x_t_particles_xs)\n",
    "            x_t_particle_d.set_ydata(x_t_particles_ys)\n",
    "            \n",
    "        if untrained_linear_data is not None:\n",
    "            untrained_linear_x_t_plus_1 = untrained_linear_data[t]\n",
    "            untrained_linear_x_next_data.set_offsets([untrained_linear_x_t_plus_1[0],  untrained_linear_x_t_plus_1[1]])\n",
    "        if untrained_linear_data is not None:\n",
    "            trained_linear_x_t_plus_1 = trained_linear_data[t]\n",
    "            trained_linear_x_next_data.set_offsets([trained_linear_x_t_plus_1[0],  trained_linear_x_t_plus_1[1]])\n",
    "        \n",
    "        if test_x_traj is not None:\n",
    "            x_t_plus_1 = test_x_traj[t]\n",
    "            xs_next = [x_t_plus_1[0], x_t_plus_1[2], x_t_plus_1[4]]\n",
    "            ys_next = [x_t_plus_1[1], x_t_plus_1[3], x_t_plus_1[5]]\n",
    "            x_next_data.set_xdata(xs_next)\n",
    "            x_next_data.set_ydata(ys_next)\n",
    "        ax = fig.gca()\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0, T), interval=100)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# 1, 9 and 13 are interesting\n",
    "# 8 and 22 are the worst cases for the old linear models\n",
    "# 14 is accurate\n",
    "# 3 is really bad\n",
    "trajectory_idx = 23\n",
    "traj = fwd_test_x_trajs[trajectory_idx], fwd_test_u_trajs[trajectory_idx]\n",
    "particles, fwd_test_x_traj, fwd_test_u_traj = predict(fwd_model, traj, steps=49)\n",
    "untrained_linear_data = predict_linear_model(untrained_A, untrained_B, fwd_test_x_trajs[trajectory_idx], fwd_test_u_trajs[trajectory_idx])\n",
    "trained_linear_data = predict_linear_model(trained_A, trained_B, fwd_test_x_trajs[trajectory_idx], fwd_test_u_trajs[trajectory_idx])\n",
    "anim = plot_predict(particles, fwd_test_x_traj, fwd_test_u_traj, untrained_linear_data, trained_linear_data)\n",
    "anim_html = anim.to_jshtml()\n",
    "anim.save('test_ex_{}.gif'.format(trajectory_idx), writer='imagemagick', fps=20)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3,3, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.arange(10), [3])\n",
    "# np.repeat(np.arange(10), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_x = np.array([-1, 0, 0, 0, 1, 0])\n",
    "# u = np.array([0.0, -0.5])\n",
    "initial_x = fwd_test_x_trajs[23, 0]\n",
    "u = fwd_test_u_trajs[23, 0]\n",
    "print(initial_x, u)\n",
    "particles, linear_data = predict_no_ground_truth(fwd_model, initial_x, u, steps=176)\n",
    "anim = plot_predict(particles, trained_linear_data=linear_data)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_x = fwd_test_x_trajs[23, 0]\n",
    "u = fwd_test_u_trajs[23, 0]\n",
    "v1 = np.array([initial_x[3] - initial_x[1], initial_x[2]-initial_x[0]])    \n",
    "v2 = np.array([initial_x[5] - initial_x[3], initial_x[4]-initial_x[2]])    \n",
    "np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inv_prediction(inv_x, inv_y):\n",
    "    inv_x = np.expand_dims(inv_x, axis=0)\n",
    "    mu, sig = inv_model.model.predict_y(inv_x)\n",
    "    s1 = np.array([[0, 0, 0, 0, 0, 0]])\n",
    "    s2 = s1 + inv_x\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(0, 0, color='m', s=100)\n",
    "    plt.scatter(s2[0,4], s2[0,5], color='b', s=1000)\n",
    "    mu_cos = mu[0, 0]\n",
    "    lower_bound_cos = mu_cos - 1.96 * sig[0, 0]\n",
    "    upper_bound_cos = mu_cos + 1.96 * sig[0, 0]\n",
    "    mu_sin = mu[0, 1]\n",
    "    lower_bound_sin = mu_sin - 1.96 * sig[0, 1]\n",
    "    upper_bound_sin = mu_sin + 1.96 * sig[0, 1]\n",
    "    mu_mag = mu[0, 2]\n",
    "    mu_nu = np.linalg.norm(mu[0, :2])\n",
    "    lower_bound_nu = np.hypot(lower_bound_cos, lower_bound_sin)\n",
    "    upper_bound_nu = np.hypot(upper_bound_cos, upper_bound_sin)\n",
    "    plt.quiver([s1[0,4], s1[0,4], s1[0,4], s1[0,4]],\n",
    "               [s1[0,5], s1[0,5], s1[0,5], s1[0,5]],\n",
    "               [lower_bound_cos / lower_bound_nu * mu_mag, upper_bound_cos / upper_bound_nu * mu_mag, mu_cos / mu_nu * mu_mag, inv_y[0] * inv_y[2]],\n",
    "               [lower_bound_sin / lower_bound_nu * mu_mag, upper_bound_sin / upper_bound_nu * mu_mag, mu_sin / mu_nu * mu_mag, inv_y[1] * inv_y[2]],\n",
    "               color=['r', 'r', 'g', 'k'],\n",
    "               width=0.005,\n",
    "               scale=1.5,\n",
    "              )\n",
    "    plt.axis(\"equal\")\n",
    "    custom_lines = [Line2D([0], [0], color='red', lw=1),\n",
    "                    Line2D([0], [0], color='green', lw=1),\n",
    "                    Line2D([0], [0], color='black', lw=1),\n",
    "                   ]\n",
    "\n",
    "    l = plt.legend(custom_lines, ['95% confidence bounds', 'mean', 'true'])\n",
    "    \n",
    "for i in range(10):\n",
    "    test_idx = 50 * i\n",
    "    plot_inv_prediction(inv_test_x[test_idx], inv_test_y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sig = inv_model.model.predict_y(test_inverse_combined_x)\n",
    "print(np.min(mu, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling the GP prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x_star = np.random.randn(1,8)\n",
    "fwd_model.model.predict_y(x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x_star = np.random.randn(1,6)\n",
    "inv_model.model.predict_y(x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
